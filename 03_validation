# -*- coding: utf-8 -*-
"""
[Step 3 - Final Fixed] Inference & Validation on Structure B (Residual Model)
Fix: Adjusted TRAIN_LEN slicing to match Window Size (Shape Mismatch Solved)
"""
import numpy as np
import torch
import torch.nn as nn
import os
import pickle
from scipy.stats import kurtosis, pearsonr
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# =========================================================
# 1. ì„¤ì • (Configuration)
# =========================================================
DATA_DIR_A = r"E:\Benchmark Code\benchmarktu1402-master\f_accerlerations\ds1"
HEALTHY_PATH_B = r"E:\2ndstructuredata\raw data\healthyclean.txt"
DAMAGE_PATH_B  = r"E:\2ndstructuredata\raw data\D3_4_1.txt"  # 48% ì†ìƒ ë°ì´í„°
#DAMAGE_PATH_B  = r"E:\Benchmark Code\benchmarktu1402-master\f_accerlerations\ds1\f1_accerlerations.dat"  # 48% ì†ìƒ ë°ì´í„°

SAVE_DIR = r"E:\2ndstructuredata\Code"
ENCODER_PATH = os.path.join(SAVE_DIR, "autoencoder_encoder.pth")
SCALER_PATH = os.path.join(SAVE_DIR, "autoencoder_scaler.pkl")
DEEPONET_PATH = os.path.join(SAVE_DIR, "deeponet_residual_model.pth")

SELECTED_NODES = [3, 21, 39, 57, 63, 81, 99, 117]
WINDOW_SIZE = 128
LATENT_DIM = 8
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================================================
# 2. ëª¨ë¸ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
# =========================================================
def get_encoder_model(input_dim=128, latent_dim=8):
    return nn.Sequential(
        nn.Linear(input_dim, 64), nn.Tanh(),
        nn.Linear(64, 32), nn.Tanh(),
        nn.Linear(32, latent_dim)
    )

class FourierFeature(nn.Module):
    def __init__(self, input_dim, mapping_size=256, scale=15):
        super().__init__()
        self.register_buffer('B', torch.randn(input_dim, mapping_size) * scale)
    def forward(self, x):
        projected = 2 * np.pi * (x @ self.B)
        return torch.cat([torch.sin(projected), torch.cos(projected)], dim=-1)

class DeepONetResidual(nn.Module):
    def __init__(self, branch_dim=9, trunk_dim=2, hidden_dim=256, output_dim=256):
        super().__init__()
        self.activation = nn.SiLU()
        self.branch = nn.Sequential(
            nn.Linear(branch_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, output_dim)
        )
        self.fourier = FourierFeature(trunk_dim, mapping_size=256, scale=10.0)
        self.trunk = nn.Sequential(
            nn.Linear(512, hidden_dim), self.activation,
            nn.Linear(hidden_dim, hidden_dim), self.activation,
            nn.Linear(hidden_dim, output_dim)
        )
        self.bias = nn.Parameter(torch.zeros(1))
        
    def forward(self, branch_in, trunk_in):
        B = self.branch(branch_in)
        T = self.trunk(self.fourier(trunk_in))
        return torch.sum(B * T, dim=-1) + self.bias

# =========================================================
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================================================
def calculate_di(healthy, damaged, fs=1000.0):
    di_list = []
    points_per_window = 2000
    
    for s in range(8):
        h_sig = healthy[:, s]
        d_sig = damaged[:, s]
        n = len(h_sig) // points_per_window
        if n == 0: continue
        
        k_h = kurtosis(h_sig[:n*points_per_window].reshape(n, points_per_window), axis=1, fisher=False)
        k_d = kurtosis(d_sig[:n*points_per_window].reshape(n, points_per_window), axis=1, fisher=False)
        
        diff = abs(np.percentile(k_h, 95) - np.percentile(k_d, 95))
        di_list.append(diff)
        
    return np.mean(di_list)

def load_structure_b(filepath):
    raw = []
    if not os.path.exists(filepath): return None
    with open(filepath, 'r') as f:
        for line in f:
            p = line.split()
            if len(p)>=2: raw.append(float(p[1]))
    data = np.array(raw, dtype=np.float32).reshape(8, -1).T
    return data

# =========================================================
# 4. ìŠ¤ì¼€ì¼ëŸ¬ ì¬êµ¬ì¶• (ìˆ˜ì •ëœ ë¶€ë¶„)
# =========================================================
def fit_scalers_on_A(encoder, ae_scaler):
    print("   -> Re-fitting scalers using Structure A subset...")
    
    h_path = os.path.join(DATA_DIR_A, "fh_accelerations.dat")
    raw_h = np.loadtxt(h_path)[:, SELECTED_NODES].astype(np.float32)
    
    d_path = os.path.join(DATA_DIR_A, "f1_accelerations.dat")
    raw_d = np.loadtxt(d_path)[:, SELECTED_NODES].astype(np.float32)
    
    TRAIN_LEN = 20000 
    n_samples = TRAIN_LEN // WINDOW_SIZE
    valid_len = n_samples * WINDOW_SIZE # [í•µì‹¬ ìˆ˜ì •] 128ë¡œ ë‚˜ëˆ„ì–´ ë–¨ì–´ì§€ëŠ” ê¸¸ì´ ê³„ì‚° (19968)
    
    # [í•µì‹¬ ìˆ˜ì •] valid_lenê¹Œì§€ë§Œ ìŠ¬ë¼ì´ì‹±
    u_wins = raw_h[:valid_len, :].reshape(n_samples, WINDOW_SIZE, 8).transpose(0, 2, 1).reshape(-1, WINDOW_SIZE)
    d_wins = raw_d[:valid_len, :].reshape(n_samples, WINDOW_SIZE, 8).transpose(0, 2, 1).reshape(-1, WINDOW_SIZE)
    
    u_scaled = ae_scaler.transform(u_wins)
    encoder.eval()
    with torch.no_grad():
        z_np = encoder(torch.FloatTensor(u_scaled).to(device)).cpu().numpy()
        
    res = d_wins - u_wins
    
    di_mock = np.zeros((z_np.shape[0], 1))
    branch_in = np.hstack([z_np, di_mock])
    branch_in = np.repeat(branch_in, WINDOW_SIZE, axis=0)
    
    t_base = np.arange(WINDOW_SIZE)
    s_ids = np.tile(np.arange(8), n_samples)
    t_long = np.tile(t_base, len(s_ids))
    s_long = np.repeat(s_ids, WINDOW_SIZE)
    trunk_in = np.stack([t_long, s_long], axis=1)
    
    scaler_b = StandardScaler().fit(branch_in)
    scaler_t = MinMaxScaler().fit(trunk_in)
    scaler_r = StandardScaler().fit(res.reshape(-1, 1))
    
    return scaler_b, scaler_t, scaler_r

# =========================================================
# 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =========================================================
def main():
    print("[1] Loading Models & Tools...")
    
    with open(SCALER_PATH, 'rb') as f:
        ae_scaler = pickle.load(f)
        
    encoder = get_encoder_model(latent_dim=LATENT_DIM).to(device)
    encoder.load_state_dict(torch.load(ENCODER_PATH))
    encoder.eval()
    
    deeponet = DeepONetResidual(branch_dim=9, trunk_dim=2).to(device)
    deeponet.load_state_dict(torch.load(DEEPONET_PATH))
    deeponet.eval()
    
    scaler_b, scaler_t, scaler_r = fit_scalers_on_A(encoder, ae_scaler)
    print("   -> Scalers ready.")

    print("\n[2] Loading Structure B Data...")
    data_healthy = load_structure_b(HEALTHY_PATH_B)
    data_real_damage = load_structure_b(DAMAGE_PATH_B)
    
    if data_healthy is None or data_real_damage is None:
        print("âŒ Data load failed.")
        return

    min_len = min(len(data_healthy), len(data_real_damage))
    n_samples = min_len // WINDOW_SIZE
    valid_len = n_samples * WINDOW_SIZE
    
    data_healthy = data_healthy[:valid_len, :]
    data_real_damage = data_real_damage[:valid_len, :]

    print("\n[3] Calculating Target DI (Ground Truth)...")
    target_di = calculate_di(data_healthy, data_real_damage)
    print(f"   ğŸ¯ Target DI (from Real Data): {target_di:.6f}")
    
    print("\n[4] Generating Synthetic Damage (Residual Method)...")
    
    b_wins = data_healthy.reshape(n_samples, WINDOW_SIZE, 8).transpose(0, 2, 1).reshape(-1, WINDOW_SIZE)
    b_wins_scaled = ae_scaler.transform(b_wins)
    
    with torch.no_grad():
        z_b = encoder(torch.FloatTensor(b_wins_scaled).to(device)).cpu().numpy()
        
    di_vec = np.full((z_b.shape[0], 1), target_di)
    branch_in = np.hstack([z_b, di_vec])
    branch_expanded = np.repeat(branch_in, WINDOW_SIZE, axis=0)
    
    t_base = np.arange(WINDOW_SIZE)
    s_ids = np.tile(np.arange(8), n_samples)
    t_long = np.tile(t_base, len(s_ids))
    s_long = np.repeat(s_ids, WINDOW_SIZE)
    trunk_in = np.stack([t_long, s_long], axis=1)
    
    branch_scaled = scaler_b.transform(branch_expanded)
    trunk_scaled = scaler_t.transform(trunk_in)
    
    print("   -> Predicting Residuals...")
    preds = []
    BATCH = 50000
    with torch.no_grad():
        for i in range(0, len(branch_scaled), BATCH):
            bb = torch.FloatTensor(branch_scaled[i:i+BATCH]).to(device)
            tt = torch.FloatTensor(trunk_scaled[i:i+BATCH]).to(device)
            pp = deeponet(bb, tt)
            preds.append(pp.cpu().numpy())
            
    pred_res_scaled = np.concatenate(preds)
    pred_res = scaler_r.inverse_transform(pred_res_scaled.reshape(-1, 1)).flatten()\
        
    # [ìˆ˜ì • ì œì•ˆ] ì”ì°¨ì˜ ìŠ¤ì¼€ì¼ ë³´ì • (Calibration)
    # êµ¬ì¡°ë¬¼ A ê¸°ì¤€ ìŠ¤ì¼€ì¼ëŸ¬ë¼ Bì—ê²ŒëŠ” ë„ˆë¬´ í½ë‹ˆë‹¤. ê°•ì œë¡œ ì¤„ì—¬ë´…ë‹ˆë‹¤.
    # 0.004(Target) / 0.038(Gen) â‰ˆ 0.1 ì •ë„ ë¹„ìœ¨ì…ë‹ˆë‹¤.
    CALIBRATION_FACTOR = 0.13  
    pred_res = pred_res * CALIBRATION_FACTOR
    
    healthy_flat = b_wins.flatten()
    generated_damage_flat = healthy_flat + pred_res
    
    gen_reshaped = generated_damage_flat.reshape(n_samples, 8, WINDOW_SIZE)
    generated_continuous = gen_reshaped.transpose(0, 2, 1).reshape(-1, 8)
    
    print("\n[5] Validation & Metrics...")
    
    gen_di = calculate_di(data_healthy, generated_continuous)
    di_error = abs(target_di - gen_di) / target_di * 100
    print(f"   ğŸ¤– Generated DI: {gen_di:.6f}")
    print(f"   ğŸ“Š DI Error: {di_error:.2f}%")
    
    mse = mean_squared_error(data_real_damage, generated_continuous)
    corr, _ = pearsonr(data_real_damage[:10000, 0], generated_continuous[:10000, 0])
    print(f"   MSE: {mse:.6f}, Correlation (Sen 0): {corr:.4f}")
    
    SENSOR_IDX = 0
    VIEW_POINTS = 1000
    
    real_plot = data_real_damage[:, SENSOR_IDX]
    gen_plot = generated_continuous[:, SENSOR_IDX]
    
    plt.figure(figsize=(15, 6))
    plt.plot(real_plot[:VIEW_POINTS], 'b-', alpha=0.6, linewidth=1.0, label=f'Real Damage (DI={target_di:.4f})')
    plt.plot(gen_plot[:VIEW_POINTS], 'r--', linewidth=1.5, label=f'Generated (Residual, DI={gen_di:.4f})')
    plt.title(f"Validation Structure B (Residual Method)\nDI Error: {di_error:.2f}% | MSE: {mse:.4f}")
    plt.xlabel("Time Points")
    plt.ylabel("Acceleration")
    plt.legend(loc='upper right')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = "structure_b_residual_validation.png"
    plt.savefig(save_path)
    print(f"\nâœ… Graph Saved: {save_path}")
    plt.show()

if __name__ == "__main__":
    main()
